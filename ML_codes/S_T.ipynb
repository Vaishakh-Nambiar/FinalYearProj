{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBtxSS_LzqpH"
      },
      "source": [
        "# Trials:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yuZd5XLu2vv2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name '_C' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertModel\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, Concatenate, Flatten\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
            "File \u001b[1;32mc:\\Users\\vaish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     logging,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     50\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\vaish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
            "File \u001b[1;32mc:\\Users\\vaish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\__init__.py:31\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     25\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     30\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     ContextManagers,\n\u001b[0;32m     33\u001b[0m     ExplicitEnum,\n\u001b[0;32m     34\u001b[0m     ModelOutput,\n\u001b[0;32m     35\u001b[0m     PaddingStrategy,\n\u001b[0;32m     36\u001b[0m     TensorType,\n\u001b[0;32m     37\u001b[0m     add_model_info_to_auto_map,\n\u001b[0;32m     38\u001b[0m     cached_property,\n\u001b[0;32m     39\u001b[0m     can_return_loss,\n\u001b[0;32m     40\u001b[0m     expand_dims,\n\u001b[0;32m     41\u001b[0m     find_labels,\n\u001b[0;32m     42\u001b[0m     flatten_dict,\n\u001b[0;32m     43\u001b[0m     infer_framework,\n\u001b[0;32m     44\u001b[0m     is_jax_tensor,\n\u001b[0;32m     45\u001b[0m     is_numpy_array,\n\u001b[0;32m     46\u001b[0m     is_tensor,\n\u001b[0;32m     47\u001b[0m     is_tf_symbolic_tensor,\n\u001b[0;32m     48\u001b[0m     is_tf_tensor,\n\u001b[0;32m     49\u001b[0m     is_torch_device,\n\u001b[0;32m     50\u001b[0m     is_torch_dtype,\n\u001b[0;32m     51\u001b[0m     is_torch_tensor,\n\u001b[0;32m     52\u001b[0m     reshape,\n\u001b[0;32m     53\u001b[0m     squeeze,\n\u001b[0;32m     54\u001b[0m     strtobool,\n\u001b[0;32m     55\u001b[0m     tensor_size,\n\u001b[0;32m     56\u001b[0m     to_numpy,\n\u001b[0;32m     57\u001b[0m     to_py_obj,\n\u001b[0;32m     58\u001b[0m     transpose,\n\u001b[0;32m     59\u001b[0m     working_or_temp_dir,\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     62\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[0;32m     63\u001b[0m     DISABLE_TELEMETRY,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m     try_to_load_from_cache,\n\u001b[0;32m     91\u001b[0m )\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     93\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[0;32m     94\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m     torch_required,\n\u001b[0;32m    198\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\vaish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:432\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_torch_pytree\u001b[39;00m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_pytree.Context\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mvalues()), (\u001b[38;5;28mtype\u001b[39m(output), \u001b[38;5;28mlist\u001b[39m(output\u001b[38;5;241m.\u001b[39mkeys()))\n",
            "File \u001b[1;32mc:\\Users\\vaish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:457\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    459\u001b[0m         __all__\u001b[38;5;241m.\u001b[39mappend(name)\n",
            "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, Flatten\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4C7GqTS2qhl",
        "outputId": "fce26668-ef94-4324-d152-f71c13c53e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   26.84    -2.68    23.09 -1014.33]\n",
            " [   30.19   -23.72    23.3  -1011.56]\n",
            " [   29.48     1.24    19.01 -1012.23]\n",
            " ...\n",
            " [   28.08    -8.38    31.9  -1024.12]\n",
            " [   27.01    -1.48    19.46 -1019.94]\n",
            " [   25.69   -23.31    26.69 -1028.95]]\n",
            "------------------------\n",
            "[26.84 30.19 29.48 ... 28.08 27.01 25.69]\n"
          ]
        }
      ],
      "source": [
        "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
        "# Assuming your dataset has columns: 'Temperature', 'Vibration_X', 'Vibration_Y', 'Vibration_Z', and 'Target'\n",
        "# dataset = pd.read_csv(\"data_1.csv\")\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/V Sem7/End-Sem Project/Data/Material 1/data_1.csv\")\n",
        "\n",
        "# Extract features and target variable\n",
        "X = dataset[[\"Temperature\", \"Vibration_X\", \"Vibration_Y\", \"Vibration_Z\"]].values\n",
        "\n",
        "#  Confusion here is with the 'target' value... letss see\n",
        "# y = dataset[\"Target\"].values\n",
        "y = dataset[\"Temperature\"].values\n",
        "\n",
        "\n",
        "print(X)\n",
        "print('------------------------')\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_hVk4oI20eT"
      },
      "outputs": [],
      "source": [
        "# Normalize the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_3wWbvj2520"
      },
      "outputs": [],
      "source": [
        "X_train_3d = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR4ZEbeQ8uV_",
        "outputId": "91b787eb-a723-4810-e4ce-a2ca4b2f3c43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0.78473091, 0.06742323, 0.50016683, 0.04126984]],\n",
              "\n",
              "       [[0.17897372, 0.06909212, 0.75008342, 0.2037037 ]],\n",
              "\n",
              "       [[0.79474343, 0.6975968 , 0.00734067, 0.31693122]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.89111389, 0.3411215 , 0.95762429, 0.12010582]],\n",
              "\n",
              "       [[0.54443054, 0.34445928, 0.67600934, 0.61851852]],\n",
              "\n",
              "       [[0.61451815, 0.12917223, 0.40707374, 0.02433862]]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_3d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UzcIVjAzyb7"
      },
      "source": [
        "--------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp50EJ41z0VU"
      },
      "source": [
        "# Trying logic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3BlpbUf0VIU"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import LSTM, Dense, Input, Concatenate, Attention\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=(X.shape[1], 1))\n",
        "\n",
        "# Create Stacked LSTM models with Transformer-like layers\n",
        "model_vibration = Sequential()\n",
        "model_temperature = Sequential()\n",
        "\n",
        "# Add Stacked LSTM layers\n",
        "model_vibration.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "model_vibration.add(LSTM(units=50, activation='relu'))\n",
        "model_vibration.add(Dense(units=X.shape[1]))  # Output layer for vibration\n",
        "\n",
        "model_temperature.add(LSTM(units=50, activation='relu', return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "model_temperature.add(LSTM(units=50, activation='relu'))\n",
        "model_temperature.add(Dense(units=1))  # Output layer for temperature\n",
        "\n",
        "# Apply Attention mechanism\n",
        "attention_vibration = Attention()([model_vibration(input_layer), input_layer])\n",
        "attended_vibration = Concatenate(axis=-1)([input_layer, attention_vibration])\n",
        "output_vibration = Dense(units=X.shape[1])(attended_vibration)\n",
        "\n",
        "attention_temperature = Attention()([model_temperature(input_layer), input_layer])\n",
        "attended_temperature = Concatenate(axis=-1)([input_layer, attention_temperature])\n",
        "output_temperature = Dense(units=1)(attended_temperature)\n",
        "\n",
        "# Create the final model\n",
        "model_vibration = Model(inputs=input_layer, outputs=output_vibration)\n",
        "model_temperature = Model(inputs=input_layer, outputs=output_temperature)\n",
        "\n",
        "# Compile the models\n",
        "model_vibration.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_temperature.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the models\n",
        "model_vibration.fit(X_stacked_lstm_transformer, y_vibration, epochs=100, batch_size=32)\n",
        "model_temperature.fit(X_stacked_lstm_transformer, y_temperature, epochs=100, batch_size=32)\n",
        "\n",
        "# Predict the 11th day values\n",
        "X_11th_day_stacked_lstm_transformer = np.array(X.iloc[[-1]]).reshape(1, X.shape[1], 1)\n",
        "vibration_11th_day_prediction_stacked_lstm_transformer = model_vibration.predict(X_11th_day_stacked_lstm_transformer)\n",
        "temperature_11th_day_prediction_stacked_lstm_transformer = model_temperature.predict(X_11th_day_stacked_lstm_transformer)\n",
        "\n",
        "# Actual values for the 11th day\n",
        "actual_vibration_11th_day = np.array([[-10, 18, -1018]])  # Replace with the actual values\n",
        "actual_temperature_11th_day = 30.0  # Replace with the actual value\n",
        "\n",
        "# Calculate errors\n",
        "vibration_error_stacked_lstm_transformer = np.abs(vibration_11th_day_prediction_stacked_lstm_transformer[0] - actual_vibration_11th_day)\n",
        "temperature_error_stacked_lstm_transformer = np.abs(temperature_11th_day_prediction_stacked_lstm_transformer[0][0] - actual_temperature_11th_day)\n",
        "\n",
        "# Display results\n",
        "print(\"Stacked LSTM with Transformer-like layer - Actual Vibration on the 11th day:\", actual_vibration_11th_day)\n",
        "print(\"Stacked LSTM with Transformer-like layer - Predicted Vibration on the 11th day:\", vibration_11th_day_prediction_stacked_lstm_transformer[0])\n",
        "print(\"Stacked LSTM with Transformer-like layer - Vibration Error for the 11th day:\", vibration_error_stacked_lstm_transformer)\n",
        "\n",
        "print(\"\\nStacked LSTM with Transformer-like layer - Actual Temperature on the 11th day:\", actual_temperature_11th_day)\n",
        "print(\"Stacked LSTM with Transformer-like layer - Predicted Temperature on the 11th day:\", temperature_11th_day_prediction_stacked_lstm_transformer[0][0])\n",
        "print(\"Stacked LSTM with Transformer-like layer - Temperature Error for the 11th day:\", temperature_error_stacked_lstm_transformer)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BBtxSS_LzqpH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
